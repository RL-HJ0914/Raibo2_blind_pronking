record_video: no
seed: 3
wandb_log: True

environment:
  seed: 3
  ip: 8080
  render: True
  num_envs: 300
  eval_every_n: 100
  iteration_per_save: 500
  iteration_per_record: 300
  num_threads: 120
  simulation_dt: 0.0025
  control_dt: 0.01
  max_time: 4.0
  iteration_per_log: 50
  randomization:
    test_mode: False
    terrain_randomization: True
    observation_randomization: True
    joint_friction_randomization: True
    voltage_randomization: False
    simulation_dt_randomization: False
    gain_randomization: False
    kinematics_randomization: False
    base_inertia_parameter_randomization: False
  reward:
    command_tracking_reward_coeff: 1.5
    airtime_reward_coeff: 0.9
    base_height_reward_coeff: 0.5
    foot_clearance_reward_coeff: -120.0
    foot_vel_before_contact_reward_coeff: -0.4
    base_motion_reward_coeff: -20.0
    torque_reward_coeff: -2.0e-4
    joint_velocity_reward_coeff: -1.6e-3
    joint_accel_reward_coeff: -1.0e-2
    nominal_pos_reward_coeff: -2.0
    joint_roll_pos_reward_coeff: -2.5
    smooth_reward1_coeff: -5.0
    smooth_reward2_coeff: -10.0
    slip_reward_coeff: -8.0e-2
    joint_limit_reward_coeff: -1.0
    bound_reward_coeff: 1.0
    positive_reward_coeff: 1.0
    negative_reward_coeff: 1.0
    GRF_smooth_reward_coeff: 0 #-3.0e-6
    undesired_contact_reward_coeff: 0 #-1.0
    joint_power_reward_coeff: 0 #-2.0e-3
    undesired_GRF_reward_coeff: 0 #-1.0e-2
    flight_phase_reward_coeff: 0 #-2.0
    torque_smooth_reward_coeff: 0 #-1.0e-10
    orientation_reward_coeff: 0 #-1.0
  curriculum:
    iteration_per_update: 5
    iteration_per_terrain_update: 40
    initial_factor: 0.2
    decay_factor: 0.97
    terrain_initial_factor: 0.01
    terrain_decay_factor: 0.97
    target_learning_episode_end: 10000
    target_smoothness_end: 1

architecture:
  hidden_dim: 128
  mlp_shape: [256, 128]
  mlp3_shape: [512, 256, 128]
